{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ab7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "import random \n",
    "\n",
    "all_stops_frame=pd.read_csv('canonical_frame_stops_SUMMARY.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "235a1b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ex_num(text):\n",
    "    numbers= re.findall(r'\\d', text)\n",
    "    cmb=int(''.join(numbers))\n",
    "    return cmb\n",
    "truncating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcdf879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique Patient Ids\n",
    "unique_ids=np.unique(all_stops_frame['#Participant_id'])\n",
    "print('Unique ids, n=', len(unique_ids))\n",
    "\n",
    "# stop_gained versus frameshift\n",
    "print('Stop gained, n=', sum(all_stops_frame['Consequence'].isin( [ 'stop_gained', 'stop_gained-frameshift_variant', 'stop_gained-inframe_deletion',     'stop_gained-protein_altering_variant',      'stop_gained-splice_region_variant'])))\n",
    "print('Frameshift, n=', sum(all_stops_frame['Consequence'].isin(['frameshift_variant','frameshift_variant-splice_region_variant',       'frameshift_variant-stop_lost'])))\n",
    "print('Stop gained / Frameshift, n=', sum(all_stops_frame['Consequence'].isin( [ 'stop_gained', 'stop_gained-frameshift_variant', 'stop_gained-inframe_deletion',     'stop_gained-protein_altering_variant',      'stop_gained-splice_region_variant']))/  sum(all_stops_frame['Consequence'].isin(['frameshift_variant','frameshift_variant-splice_region_variant',       'frameshift_variant-stop_lost'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa03795b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove downstream SAMP\n",
    "protein_position=[]\n",
    "for i in np.arange(len(all_stops_frame)):\n",
    "    \n",
    "    if len(all_stops_frame['Protein_position'][i])>8:\n",
    "        protein_position.append(int(all_stops_frame['Protein_position'][i][0:4]))\n",
    "    elif len(all_stops_frame['Protein_position'][i])>5:\n",
    "        protein_position.append(int(all_stops_frame['Protein_position'][i][0:3]))\n",
    "    elif len(all_stops_frame['Protein_position'][i])>4:\n",
    "        protein_position.append(int(all_stops_frame['Protein_position'][i][0:2]))\n",
    "    else:\n",
    "        protein_position.append(int(all_stops_frame['Protein_position'][i]))\n",
    "all_stops_frame['Position']=protein_position\n",
    "\n",
    "A=len(all_stops_frame)\n",
    "all_stops_frame=all_stops_frame[all_stops_frame['Position']<1590]\n",
    "print('Remove alterations after SAMP, n=',A-len(all_stops_frame) )\n",
    "\n",
    "# unique Patient Ids\n",
    "unique_ids=np.unique(all_stops_frame['#Participant_id'])\n",
    "print('Unique ids, n=', len(unique_ids))\n",
    "\n",
    "\n",
    "# stop_gained versus frameshift\n",
    "cons=[]\n",
    "for i in all_stops_frame['Consequence']:\n",
    "    if i in [ 'stop_gained', 'stop_gained-frameshift_variant', 'stop_gained-inframe_deletion',     'stop_gained-protein_altering_variant',      'stop_gained-splice_region_variant']:\n",
    "        cons.append('stop_gained')\n",
    "    if i in ['frameshift_variant','frameshift_variant-splice_region_variant',       'frameshift_variant-stop_lost']:\n",
    "        cons.append('frameshift')\n",
    "all_stops_frame['Type']=cons\n",
    "\n",
    "\n",
    "\n",
    "print('Stop gained, n=', sum(all_stops_frame['Consequence'].isin( [ 'stop_gained', 'stop_gained-frameshift_variant', 'stop_gained-inframe_deletion',     'stop_gained-protein_altering_variant',      'stop_gained-splice_region_variant'])))\n",
    "print('Frameshift, n=', sum(all_stops_frame['Consequence'].isin(['frameshift_variant','frameshift_variant-splice_region_variant',       'frameshift_variant-stop_lost'])))\n",
    "print('Stop gained / Frameshift, n=', sum(all_stops_frame['Consequence'].isin( [ 'stop_gained', 'stop_gained-frameshift_variant', 'stop_gained-inframe_deletion',     'stop_gained-protein_altering_variant',      'stop_gained-splice_region_variant']))/  sum(all_stops_frame['Consequence'].isin(['frameshift_variant','frameshift_variant-splice_region_variant',       'frameshift_variant-stop_lost'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f973a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store region\n",
    "\n",
    "regions=[]\n",
    "for i in all_stops_frame['Position']:\n",
    "    if i< 1256:\n",
    "        regions.append(0)\n",
    "    elif i< 1370:\n",
    "        regions.append(1)\n",
    "    elif i<1486:\n",
    "        regions.append(2)\n",
    "    else:\n",
    "        regions.append(3)\n",
    "\n",
    "all_stops_frame['Region']=regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6732a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique Patient Ids\n",
    "unique_ids,counts=np.unique(all_stops_frame['#Participant_id'],return_counts=True)\n",
    "U=len(unique_ids)\n",
    "region=[]\n",
    "types=[]\n",
    "ids=[]\n",
    "mutations=[]\n",
    "i=0\n",
    "\n",
    "\n",
    "all_stops_frame=all_stops_frame.reset_index(drop=True)\n",
    "\n",
    "for u in unique_ids:\n",
    "    ids.append(u)\n",
    "    patient_u=all_stops_frame[all_stops_frame['#Participant_id']==u]\n",
    "    region.append(np.asarray(patient_u['Region']))\n",
    "    mutations.append(np.asarray(patient_u['Position']))\n",
    "    \n",
    "    types.append(np.asarray(patient_u['Type']))\n",
    "details={'Participant_ID':ids,'Regions':region,'Types':types,'Position':mutations}\n",
    "All_mutations = pd.DataFrame(details)\n",
    "All_mutations.to_csv('All_APC_mutations.csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7426bb0b",
   "metadata": {},
   "source": [
    "## Add copy-number alterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "800715d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy_number=pd.read_csv('APC_copy_number.csv',sep=\",\")\n",
    "copy_number=pd.read_csv('Landscape_data/CN_landscape_chr5.csv')\n",
    "\n",
    "# filter for cn affecting APC region \n",
    "copy_number=copy_number[copy_number['APC']==1].reset_index(drop=True)\n",
    "# fill na as not known\n",
    "copy_number.fillna('nk')\n",
    "\n",
    "cn1=[]\n",
    "cn2=[]\n",
    "frac1=[]\n",
    "frac2=[]\n",
    "copy_number.keys()\n",
    "\n",
    "U=len(All_mutations)\n",
    "ids=All_mutations['Participant_ID']\n",
    "\n",
    "\n",
    "for i in np.arange(U):\n",
    "    index_id=np.where(ids[i]==copy_number['ids'])[0]\n",
    "    \n",
    "    # if no copy number inforamtion was found\n",
    "    \n",
    "    if len(index_id)==0:\n",
    "        frac1.append('nk')\n",
    "        cn1.append('nk')\n",
    "        frac2.append('nk')\n",
    "        cn2.append('nk')\n",
    "    \n",
    "    # else store the\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        frac1.append(copy_number['frac1_A'][index_id[0]])\n",
    "        frac2.append(copy_number['frac1_B'][index_id[0]])\n",
    "        \n",
    "        cn_A=[copy_number['nMaj1_A'][index_id[0]],copy_number['nMin1_A'][index_id[0]]]\n",
    "        cn1.append(cn_A)\n",
    "        cn_B=[copy_number['nMaj1_B'][index_id[0]],copy_number['nMin1_B'][index_id[0]]]\n",
    "        cn2.append(cn_B)\n",
    "\n",
    "All_mutations['Copy_number_1']=cn1\n",
    "All_mutations['Frac_1']=frac1\n",
    "All_mutations['Copy_number_2']=cn2\n",
    "All_mutations['Frac_2']=frac2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b099b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save separately samples with subclones\n",
    "\n",
    "sub=All_mutations[All_mutations['Frac_1']!=1]\n",
    "sub=sub[sub['Copy_number_1']!='nk']\n",
    "sub.to_csv('subclonal.csv')#sub1=sub[sum(sub['Copy_numer_1'])!=1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40f5ad7",
   "metadata": {},
   "source": [
    "## Import Landscape analysed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "125988e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Landscape_oncogenic= pd.read_csv('Landscape_data/CRC_v8_2023_candidate_genes_194_oncogenic_matrix.tsv',sep=\"\\t\")\n",
    "\n",
    "# match ids\n",
    "\n",
    "ids_keys=pd.read_csv('Landscape_data/crc_polypy_preferred_paths.tsv',sep=\"\\t\")\n",
    "keys_lan=np.asarray(Landscape_oncogenic['Gene/Sample'])\n",
    "keys=np.asarray(ids_keys['somatic_platekey'])\n",
    "ids=np.asarray(ids_keys['participant_id'])\n",
    "ids_lan=np.zeros(len(keys_lan))\n",
    "for i in np.arange(len(keys_lan)):\n",
    "    m=keys_lan[i]\n",
    "    match=np.where(keys==m)[0]\n",
    "    if len(match)>0:\n",
    "        match=np.where(keys==m)[0][0]\n",
    "        ids_lan[i]=ids[match]\n",
    "    else: \n",
    "        ids_lan[i]=0\n",
    "Landscape_oncogenic['Participant_ID']=ids_lan\n",
    "Landscape_oncogenic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "202bf419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "All_landscape= pd.read_csv('Landscape_data/WNT_CRC_v8_2023_candidate_genes_194_oncogenic_matrix_filtered_by_patient.csv',sep=\"\\t\")\n",
    "\n",
    "# match ids\n",
    "\n",
    "ids_keys=pd.read_csv('Landscape_data/crc_polypy_preferred_paths.tsv',sep=\"\\t\")\n",
    "\n",
    "\n",
    "keys_lan=np.asarray(All_landscape['tumour_sample_platekey'])\n",
    "keys=np.asarray(ids_keys['somatic_platekey'])\n",
    "ids=np.asarray(ids_keys['participant_id'])\n",
    "ids_lan=np.zeros(len(keys_lan))\n",
    "for i in np.arange(len(keys_lan)):\n",
    "    m=keys_lan[i]\n",
    "    match=np.where(keys==m)[0]\n",
    "    if len(match)>0:\n",
    "        match=np.where(keys==m)[0][0]\n",
    "        ids_lan[i]=ids[match]\n",
    "    else: \n",
    "        ids_lan[i]=0\n",
    "All_landscape['Participant_ID']=ids_lan\n",
    "All_landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66cb3fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro= pd.read_csv('combined_data.csv',sep=\",\")\n",
    "pro=pro[['participant_id','primary_tumour_site_less_specific','WGD']]\n",
    "pro=pro.rename(columns={'participant_id':'Participant_ID', 'primary_tumour_site_less_specific':'Site'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abf2b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merge_Landscape=pd.merge(All_mutations,All_landscape,on='Participant_ID')\n",
    "Merge_Landscape=pd.merge(Merge_Landscape,pro,on='Participant_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "872e5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merge_Landscape_Oncogenic=pd.merge(Merge_Landscape,Landscape_oncogenic,on='Participant_ID',suffixes=('_',''))\n",
    "Merge_Landscape_Oncogenic=Merge_Landscape_Oncogenic.loc[:,~Merge_Landscape_Oncogenic.columns.duplicated()]\n",
    "All_APC_Landscape=Merge_Landscape_Oncogenic\n",
    "All_APC_Landscape.to_csv('All_APC_Landscape.csv')\n",
    "\n",
    "print('All APC mutants in Landscape, n=',len(All_APC_Landscape))\n",
    "\n",
    "\n",
    "\n",
    "All_APC_Landscape=All_APC_Landscape[All_APC_Landscape['tumour_type']=='PRIMARY']\n",
    "print('All APC mutants in Landscape, primary, n=',len(All_APC_Landscape))\n",
    "\n",
    "\n",
    "All_APC_Landscape_MSS=All_APC_Landscape[All_APC_Landscape['subtype']=='MSS']\n",
    "print('All APC mutants in Landscape, primary MSS, n=',len(All_APC_Landscape_MSS), ' out of n=',len(All_landscape[All_landscape['subtype']=='MSS']))\n",
    "\n",
    "\n",
    "All_APC_Landscape_MSS_prox=All_APC_Landscape_MSS[All_APC_Landscape_MSS['Site']=='PROXIMAL_COLON']\n",
    "print('All APC mutants in Landscape, primary MSS, proximal, n=',len(All_APC_Landscape_MSS_prox))#, ' out of n=',len(All_landscape[All_landscape['subtype']=='MSS']))\n",
    "\n",
    "\n",
    "All_APC_Landscape_MSS_dist=All_APC_Landscape_MSS[All_APC_Landscape_MSS['Site'].isin(['RECTUM','DISTAL_COLON'])]\n",
    "print('All APC mutants in Landscape, primary MSS, distal, n=',len(All_APC_Landscape_MSS_dist))#, ' out of n=',len(All_landscape[All_landscape['subtype']=='MSS']))\n",
    "\n",
    "\n",
    "for w in ['RNF43','CTNNB1','TCF7L2','SOX9','AXIN1','AXIN2','FBXW7','ZNRF3','BCL9L','BCL9','AMER1']:\n",
    "    All_APC_Landscape_MSS_w=All_APC_Landscape_MSS[All_APC_Landscape_MSS[w]==1]\n",
    "    print('All APC mutants in Landscape, primary MSS and mutations on', w,', n=',len(All_APC_Landscape_MSS_w))\n",
    "All_APC_Landscape_MSS_w=All_APC_Landscape[All_APC_Landscape['AMER1']==1]\n",
    "\n",
    "\n",
    "All_APC_Landscape_MSI=All_APC_Landscape[All_APC_Landscape['subtype']=='MSI']\n",
    "print('All APC mutants in Landscape, primary MSI, n=',len(All_APC_Landscape_MSI),' out of n=',len(All_landscape[All_landscape['subtype']=='MSI']))\n",
    "\n",
    "\n",
    "All_APC_Landscape_POL=All_APC_Landscape[All_APC_Landscape['subtype']=='POL']\n",
    "print('All APC mutants in Landscape, primary POLE, n=',len(All_APC_Landscape_POL),' out of n=',len(All_landscape[All_landscape['subtype']=='POL']))\n",
    "\n",
    "\n",
    "All_APC_Landscape_t=All_APC_Landscape_MSS[All_APC_Landscape_MSS['systemic_therapy_prior_sampling']==False]\n",
    "print('All APC mutants in Landscape, primary and no systemic therapy, n=',len(All_APC_Landscape_t))\n",
    "\n",
    "All_APC_Landscape_MSS_tn=All_APC_Landscape_t[All_APC_Landscape_t['radiotherapy_prior_sampling']==False]\n",
    "print('All APC mutants in Landscape, primary and no systemic therapy or radiotherapy, n=',len(All_APC_Landscape_MSS_tn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "044cfabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary=All_APC_Landscape_MSS[['Regions','Types','Copy_number_1','Frac_1','Copy_number_2','Frac_2','Site','subtype','WGD','AMER1','RNF43','CTNNB1','TCF7L2','SOX9','AXIN1','AXIN2','FBXW7','ZNRF3','BCL9L','BCL9']]\n",
    "Summary['Counts']=np.ones(len(Summary))\n",
    "Summary=Summary.groupby([Summary['WGD'],Summary['Types'].apply(lambda x: tuple(x)),Summary['Regions'].apply(lambda x: tuple(x)),Summary['Copy_number_1'].apply(lambda x: tuple(x))]).agg({'Counts':'sum'})\n",
    "Summary.to_csv('MSS_WGD.csv')\n",
    "\n",
    "Summary=All_APC_Landscape_MSS_tn[['Regions','Types','Copy_number_1','Frac_1','Copy_number_2','Frac_2','Site','subtype','WGD','AMER1','RNF43','CTNNB1','TCF7L2','SOX9','AXIN1','AXIN2','FBXW7','ZNRF3','BCL9L','BCL9']]\n",
    "Summary['Counts']=np.ones(len(Summary))\n",
    "Summary=Summary.groupby([Summary['WGD'],Summary['Types'].apply(lambda x: tuple(x)),Summary['Regions'].apply(lambda x: tuple(x)),Summary['Copy_number_1'].apply(lambda x: tuple(x))]).agg({'Counts':'sum'})\n",
    "Summary.to_csv('MSS_WGD_TN.csv')\n",
    "\n",
    "\n",
    "\n",
    "Summary=All_APC_Landscape_POL[['Regions','Types','Copy_number_1','Frac_1','Copy_number_2','Frac_2','Site','subtype','WGD','AMER1','RNF43','CTNNB1','TCF7L2','SOX9','AXIN1','AXIN2','FBXW7','ZNRF3','BCL9L','BCL9']]\n",
    "Summary['Counts']=np.ones(len(Summary))\n",
    "Summary=Summary.groupby([Summary['WGD'],Summary['Types'].apply(lambda x: tuple(x)),Summary['Regions'].apply(lambda x: tuple(x)),Summary['Copy_number_1'].apply(lambda x: tuple(x))]).agg({'Counts':'sum'})\n",
    "Summary.to_csv('POLE_WGD.csv')\n",
    "\n",
    "Summary=All_APC_Landscape_MSS_prox[['Regions','Types','Copy_number_1','Frac_1','Copy_number_2','Frac_2','Site','subtype','WGD','AMER1','RNF43','CTNNB1','TCF7L2','SOX9','AXIN1','AXIN2','FBXW7','ZNRF3','BCL9L','BCL9']]\n",
    "Summary['Counts']=np.ones(len(Summary))\n",
    "Summary=Summary.groupby([Summary['WGD'],Summary['Types'].apply(lambda x: tuple(x)),Summary['Regions'].apply(lambda x: tuple(x)),Summary['Copy_number_1'].apply(lambda x: tuple(x))]).agg({'Counts':'sum'})\n",
    "Summary.to_csv('MSS_P_WGD.csv')\n",
    "\n",
    "\n",
    "\n",
    "Summary=All_APC_Landscape_MSS_dist[['Regions','Types','Copy_number_1','Frac_1','Copy_number_2','Frac_2','Site','subtype','WGD','AMER1','RNF43','CTNNB1','TCF7L2','SOX9','AXIN1','AXIN2','FBXW7','ZNRF3','BCL9L','BCL9']]\n",
    "Summary['Counts']=np.ones(len(Summary))\n",
    "Summary=Summary.groupby([Summary['WGD'],Summary['Types'].apply(lambda x: tuple(x)),Summary['Regions'].apply(lambda x: tuple(x)),Summary['Copy_number_1'].apply(lambda x: tuple(x))]).agg({'Counts':'sum'})\n",
    "Summary.to_csv('MSS_D_WGD.csv')\n",
    "\n",
    "\n",
    "\n",
    "Summary=All_APC_Landscape_MSS_w[['Regions','Types','Copy_number_1','Frac_1','Copy_number_2','Frac_2','Site','subtype','WGD','AMER1','RNF43','CTNNB1','TCF7L2','SOX9','AXIN1','AXIN2','FBXW7','ZNRF3','BCL9L','BCL9']]\n",
    "Summary['Counts']=np.ones(len(Summary))\n",
    "Summary=Summary.groupby([Summary['WGD'],Summary['Types'].apply(lambda x: tuple(x)),Summary['Regions'].apply(lambda x: tuple(x)),Summary['Copy_number_1'].apply(lambda x: tuple(x))]).agg({'Counts':'sum'})\n",
    "Summary.to_csv('MSS_AMER1_WGD.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c16daa",
   "metadata": {},
   "source": [
    "## POLE data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d40d1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "POLE=pd.read_csv('APC_POLE_v17.csv',sep=\",\")\n",
    "POLE=POLE.fillna(2000)\n",
    "POLE=POLE[POLE['Cellbase Consequence'].isin(['frameshift_variant',  'stop_gained'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cd4b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for p in list(POLE['Protein Change']):\n",
    "    truncating.append(ex_num(str(p)))\n",
    "POLE['Position']=truncating\n",
    "\n",
    "POLE=POLE[POLE['Position']<1590]\n",
    "\n",
    "# Store region\n",
    "\n",
    "regions=[]\n",
    "for i in POLE['Position']:\n",
    "    if i< 1256:\n",
    "        regions.append(0)\n",
    "    elif i< 1370:\n",
    "        regions.append(1)\n",
    "    elif i<1500:\n",
    "        regions.append(2)\n",
    "    else:\n",
    "        regions.append(3)\n",
    "\n",
    "POLE['Region']=regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590b003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b31ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique Patient Ids\n",
    "unique_ids,counts=np.unique(POLE['Participant Id'],return_counts=True)\n",
    "U=len(unique_ids)\n",
    "print(U)\n",
    "region=[]\n",
    "ids=[]\n",
    "mutations=[]\n",
    "i=0\n",
    "pole_mutation=[]\n",
    "\n",
    "all_stops_frame=all_stops_frame.reset_index(drop=True)\n",
    "\n",
    "for u in unique_ids:\n",
    "    ids.append(u)\n",
    "    patient_u=POLE[POLE['Participant Id']==u]\n",
    "    patient_u=patient_u.reset_index(drop=True)\n",
    "    region.append(np.asarray(patient_u['Region']))\n",
    "    mutations.append(np.asarray(patient_u['Position']))\n",
    "    pole_mutation.append(patient_u['Protein_Change'][0])\n",
    "\n",
    "    \n",
    "details={'Participant_ID':ids,'Regions':region,'Position':mutations, 'POLE': pole_mutation}\n",
    "All_mutations_POLE = pd.DataFrame(details)  \n",
    "All_APC_Landscape_POL=All_APC_Landscape_POL.reset_index(drop=True)\n",
    "\n",
    "All_mutations_POLE.to_csv('POLE_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11f0bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=list(All_mutations_POLE['Participant_ID'])\n",
    "\n",
    "regions=list(All_mutations_POLE['Regions'])\n",
    "for pp in np.arange(len(All_APC_Landscape_POL['Participant_ID'])):\n",
    "    p = All_APC_Landscape_POL['Participant_ID'][pp]\n",
    "    if p in list(All_mutations_POLE['Participant_ID']):\n",
    "        print('already in')\n",
    "    else:\n",
    "        ids.append(p)\n",
    "        regions.append(All_APC_Landscape_POL['Regions'][pp])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56d60c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary={'Participant_ID':ids,'Regions':regions}\n",
    "summary_POLE = pd.DataFrame(summary)  \n",
    "summary_POLE['Regions']=summary_POLE['Regions'].apply(lambda x: tuple(x))\n",
    "summary_POLE=summary_POLE.groupby('Regions').size().reset_index(name='Counts')#.count()\n",
    "\n",
    "summary_POLE.to_csv('POLE_Summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2d3eec",
   "metadata": {},
   "source": [
    "## MSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e80a4bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions=[]\n",
    "ids=[]\n",
    "All_APC_Landscape_MSI=All_APC_Landscape_MSI.reset_index(drop=True)\n",
    "for i in np.arange(len(All_APC_Landscape_MSI)):\n",
    "    if All_APC_Landscape_MSI['Copy_number_1'][i][1]> 0 and len(All_APC_Landscape_MSI['Regions'][i])>1:\n",
    "        regions.append(All_APC_Landscape_MSI['Regions'][i])\n",
    "        ids.append(All_APC_Landscape_MSI['Participant_ID'][i])\n",
    "summary={'Participant_ID':ids,'Regions':regions}\n",
    "summary_MSI = pd.DataFrame(summary)  \n",
    "summary_MSI['Regions']=summary_MSI['Regions'].apply(lambda x: tuple(x))        \n",
    "summary_MSI_all=summary_MSI.groupby('Regions').size().reset_index(name='Counts')\n",
    "\n",
    "summary_MSI_all.to_csv('MSI_Summary.csv')\n",
    "\n",
    "\n",
    "regions=[]\n",
    "ids=[]\n",
    "All_APC_Landscape_MSI_P=All_APC_Landscape_MSI[All_APC_Landscape_MSI['Site']=='PROXIMAL_COLON'].reset_index(drop=True)\n",
    "for i in np.arange(len(All_APC_Landscape_MSI_P)):\n",
    "    if All_APC_Landscape_MSI_P['Copy_number_1'][i][1]> 0 and len(All_APC_Landscape_MSI_P['Regions'][i])>1:\n",
    "        regions.append(All_APC_Landscape_MSI_P['Regions'][i])\n",
    "        ids.append(All_APC_Landscape_MSI_P['Participant_ID'][i])\n",
    "summary={'Participant_ID':ids,'Regions':regions}\n",
    "summary_MSI = pd.DataFrame(summary)  \n",
    "summary_MSI['Regions']=summary_MSI['Regions'].apply(lambda x: tuple(x))        \n",
    "summary_MSI_Proximal=summary_MSI.groupby('Regions').size().reset_index(name='Counts')#.count()\n",
    "\n",
    "summary_MSI_Proximal.to_csv('MSI_P_Summary.csv')\n",
    "\n",
    "regions=[]\n",
    "ids=[]\n",
    "All_APC_Landscape_MSI_D=All_APC_Landscape_MSI[All_APC_Landscape_MSI['Site'].isin(['RECTUM','DISTAL_COLON'])].reset_index(drop=True)\n",
    "for i in np.arange(len(All_APC_Landscape_MSI_D)):\n",
    "    if All_APC_Landscape_MSI_D['Copy_number_1'][i][1]> 0 and len(All_APC_Landscape_MSI_D['Regions'][i])>1:\n",
    "        regions.append(All_APC_Landscape_MSI_D['Regions'][i])\n",
    "        ids.append(All_APC_Landscape_MSI_D['Participant_ID'][i])\n",
    "summary={'Participant_ID':ids,'Regions':regions}\n",
    "summary_MSI = pd.DataFrame(summary)  \n",
    "summary_MSI['Regions']=summary_MSI['Regions'].apply(lambda x: tuple(x))        \n",
    "summary_MSI_Distal=summary_MSI.groupby('Regions').size().reset_index(name='Counts')#.count()\n",
    "\n",
    "summary_MSI_Distal.to_csv('MSI_D_Summary.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
